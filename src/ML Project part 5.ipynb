{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "UNKNOWN_TOKEN = \"#UNK#\"\n",
    "\n",
    "filepath = \"ML Project/EN/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file):\n",
    "    \"\"\"\n",
    "    Prepare the file, and returns a list of lists of \"{observation} {label}\"\n",
    "    file : the name of the file to read\n",
    "    \"\"\"\n",
    "\n",
    "    lines = [line for line in file]\n",
    "    chunks = (list(g) for k, g in groupby(lines, key=lambda x: x != '\\n') if k)\n",
    "    return [[observation.rstrip('\\n') for observation in chunk] for chunk in chunks]\n",
    "\n",
    "file = open(\"ML Project/EN/train\")\n",
    "sequence = prepare_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observations(sequence,k=1):\n",
    "    observationsDict = {}\n",
    "    sequence = (item for sublist in sequence for item in sublist)\n",
    "    for item in sequence:\n",
    "        observation = item.rsplit(\" \", 1)[0]\n",
    "        if observation not in observationsDict:  \n",
    "             observationsDict[observation] = 1\n",
    "        else:  \n",
    "             observationsDict[observation] += 1\n",
    "        \n",
    "    observationsList = list(observationsDict)\n",
    "    for observation in observationsDict:\n",
    "        if observationsDict[observation] < k:\n",
    "            observationsList.remove(observation)\n",
    "    \n",
    "    observationsList.append(UNKNOWN_TOKEN)\n",
    "    \n",
    "    return observationsList,observationsDict\n",
    "    \n",
    "observationsList,observationsDict = get_observations(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(sequence):\n",
    "    tagsList = []\n",
    "    sequence = (item for sublist in sequence for item in sublist)\n",
    "    for item in sequence:\n",
    "        tag = item.rsplit(\" \", 1)[1]\n",
    "        if tag not in tagsList: \n",
    "            tagsList.append(tag)\n",
    "            \n",
    "    return tagsList\n",
    "\n",
    "tagsList = get_tags(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_parameters(tagsList,sequence):\n",
    "    from_Y_List = ['START'] + tagsList\n",
    "    to_Y_List = tagsList + ['STOP']\n",
    "    length = len(from_Y_List)\n",
    "    transitionDF = pd.DataFrame(np.zeros((length,length)),index = from_Y_List,columns = to_Y_List)\n",
    "    \n",
    "    sentenceVector = []\n",
    "    for sentence in sequence:\n",
    "        observationVector = []\n",
    "        tagVector = []\n",
    "        for word in sentence:\n",
    "            observation = word.rsplit(\" \", 1)[0]\n",
    "            tag = word.rsplit(\" \", 1)[1]\n",
    "            observationVector.append(observation)\n",
    "            tagVector.append(tag)\n",
    "        sentenceVector.append([observationVector,tagVector])\n",
    "        \n",
    "    for sentence in sentenceVector:\n",
    "        observationVector,tagVector = sentence\n",
    "        length = len(observationVector)\n",
    "        for i in range(length+1):\n",
    "            if i == 0 :\n",
    "                transitionDF.loc['START',tagVector[0]] += 1\n",
    "\n",
    "            elif i == length:\n",
    "                transitionDF.loc[tagVector[i-1],'STOP'] +=1\n",
    "\n",
    "            else:\n",
    "                transitionDF.loc[tagVector[i-1],tagVector[i]] += 1\n",
    "    \n",
    "    for i in range(len(transitionDF.index)):\n",
    "        transitionDF.iloc[i,:] /= transitionDF.iloc[i,:].sum()\n",
    "            \n",
    "    return transitionDF\n",
    "\n",
    "transitionParameters = get_transition_parameters(tagsList,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_counts(sequence,observationsList,tagsList):\n",
    "    sentenceVector = []\n",
    "    for sentence in sequence:\n",
    "        observationVector = []\n",
    "        tagVector = []\n",
    "        for word in sentence:\n",
    "            observation = word.rsplit(\" \", 1)[0]\n",
    "            tag = word.rsplit(\" \", 1)[1]\n",
    "            observationVector.append(observation)\n",
    "            tagVector.append(tag)\n",
    "        sentenceVector.append([observationVector,tagVector])\n",
    "\n",
    "    observationsLength = len(observationsList)\n",
    "    tagsLength = len(tagsList)\n",
    "    emissionDF = pd.DataFrame(np.zeros((observationsLength,tagsLength)),index = observationsList,columns = tagsList)\n",
    "    emissionCount = pd.Series(np.zeros(tagsLength),index = tagsList)\n",
    "\n",
    "    for sentence in sentenceVector:\n",
    "        observationVector,tagVector = sentence\n",
    "        for i in range(len(observationVector)):\n",
    "            observation,tag = observationVector[i],tagVector[i]\n",
    "            emissionDF.loc[observation,tag] += 1\n",
    "            emissionCount[tag] += 1\n",
    "        \n",
    "    return emissionDF,emissionCount\n",
    "\n",
    "def get_smooth_emission_counts(sequence,observationsList,tagsList,k=1):\n",
    "    emissionDF,emissionCount = get_emission_counts(sequence,observationsList,tagsList)\n",
    "    \n",
    "    observationCount = emissionDF.sum(axis=1)\n",
    "    fail = observationCount[observationCount < k]\n",
    "\n",
    "    unknown = emissionDF.loc[fail.index].sum(axis=0)\n",
    "    unknown.name = UNKNOWN_TOKEN\n",
    "   \n",
    "    smoothEmissionDF = emissionDF\n",
    "    smoothEmissionDF = smoothEmissionDF.drop(fail.index, axis=0) \n",
    "    smoothEmissionDF.loc[UNKNOWN_TOKEN] = unknown    \n",
    "    \n",
    "    emissionParameters = smoothEmissionDF/emissionCount\n",
    "    return emissionParameters\n",
    "\n",
    "emissionParameters = get_smooth_emission_counts(sequence,observationsList,tagsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_emission_weights(observationsList,tagsList,emissionParameters):\n",
    "    emissionWeights = {}\n",
    "    for tag in tagsList:\n",
    "        emissionWeights[tag] = {}\n",
    "        for observation in observationsList:\n",
    "            emissionWeights[tag][observation] = [0.0,0.0]\n",
    "    \n",
    "    for tag in emissionWeights:\n",
    "        for observation in emissionWeights[tag]:\n",
    "            emissionWeights[tag][observation] = [emissionParameters[tag][observation],emissionParameters[tag][observation]]\n",
    "    \n",
    "    return emissionWeights\n",
    "\n",
    "emissionWeights = initialize_emission_weights(observationsList,tagsList,emissionParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_transition_weights(tagsList,transitionParameters):\n",
    "    transitionWeights = {}\n",
    "    from_Y_List = ['START'] + list(tagsList)\n",
    "    to_Y_List = list(tagsList) + ['STOP']\n",
    "    for from_Y_Tag in from_Y_List:\n",
    "        transitionWeights[from_Y_Tag] = {}\n",
    "        for to_Y_Tag in to_Y_List:\n",
    "            transitionWeights[from_Y_Tag][to_Y_Tag] = [0.0,0.0]\n",
    "            \n",
    "    for from_Y_Tag in transitionWeights:\n",
    "        for to_Y_Tag in transitionWeights[from_Y_Tag]:\n",
    "            transitionWeights[from_Y_Tag][to_Y_Tag] = [transitionParameters[to_Y_Tag][from_Y_Tag],transitionParameters[to_Y_Tag][from_Y_Tag]]\n",
    "    \n",
    "    return transitionWeights\n",
    "\n",
    "transitionWeights = initialize_transition_weights(tagsList,transitionParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(observationSequence,observationsList,emissionWeights,transitionWeights,tagsList):\n",
    "    pi = [{tag: [0.0, ''] for tag in tagsList} for o in observationSequence]\n",
    "\n",
    "    for tag in tagsList:\n",
    "        score = 0.0\n",
    "        score += transitionWeights['START'][tag][0]\n",
    "\n",
    "        if observationSequence[0] in observationsList: \n",
    "            score += emissionWeights[tag][observationSequence[0]][0]\n",
    "        else: \n",
    "            score += emissionWeights[tag]['#UNK#'][0]\n",
    "\n",
    "        pi[0][tag] = [score, 'START']\n",
    "\n",
    "    for k in range(1, len(observationSequence)): \n",
    "        for from_Y_Tag in tagsList:\n",
    "            for to_Y_Tag in tagsList:\n",
    "                score = pi[k-1][to_Y_Tag][0]\n",
    "                score += transitionWeights[to_Y_Tag][from_Y_Tag][0]\n",
    "\n",
    "                if score > pi[k][from_Y_Tag][0]:\n",
    "                    pi[k][from_Y_Tag] = [score, to_Y_Tag]\n",
    "\n",
    "            if observationSequence[k] in observationsList: \n",
    "                pi[k][from_Y_Tag][0] += emissionWeights[from_Y_Tag][observationSequence[k]][0]\n",
    "            else: \n",
    "                pi[k][from_Y_Tag][0] += emissionWeights[from_Y_Tag]['#UNK#'][0]\n",
    "\n",
    "    result = [0.0, '']\n",
    "    for to_Y_Tag in tagsList:\n",
    "        score = pi[-1][to_Y_Tag][0] + transitionWeights[to_Y_Tag]['STOP'][0]\n",
    "\n",
    "        if score > result[0]:\n",
    "            result = [score, to_Y_Tag]\n",
    "\n",
    "    prediction = [result[1]]\n",
    "    for k in reversed(range(len(observationSequence))):\n",
    "        if k == 0: break  \n",
    "        prediction.insert(0, pi[k][prediction[0]][1])\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# predictedTagSequence = viterbi(observationSequence,observationsList,emissionWeights,transitionWeights,tagsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWeights(observationSequence,tagSequence,predictedTagSequence,observationsList,emissionWeights,transitionWeights):\n",
    "    tagSequence.insert(0, 'START')\n",
    "    tagSequence.append('STOP')\n",
    "    predictedTagSequence.insert(0, 'START')\n",
    "    predictedTagSequence.append('STOP')\n",
    "    observationSequence.insert(0, '')\n",
    "    observationSequence.append('')\n",
    "    \n",
    "    for i in range(len(tagSequence)):\n",
    "        if tagSequence[i] != predictedTagSequence[i]:\n",
    "            if tagSequence[i]!='START' and tagSequence[i]!='STOP' and predictedTagSequence[i]!='START' and predictedTagSequence[i]!='STOP':\n",
    "                if observationSequence[i] in observationsList:  # if word is not unknown\n",
    "                    emissionWeights[tagSequence[i]][observationSequence[i]][0] += 1\n",
    "                    emissionWeights[tagSequence[i]][observationSequence[i]][1] += emissionWeights[tagSequence[i]][observationSequence[i]][0]\n",
    "\n",
    "                    emissionWeights[predictedTagSequence[i]][observationSequence[i]][0] -= 1\n",
    "                    emissionWeights[predictedTagSequence[i]][observationSequence[i]][1] += emissionWeights[predictedTagSequence[i]][observationSequence[i]][0]\n",
    "                else:  \n",
    "                    emissionWeights[tagSequence[i]]['#UNK#'][0] += 1\n",
    "                    emissionWeights[tagSequence[i]]['#UNK#'][1] += emissionWeights[tagSequence[i]]['#UNK#'][0]\n",
    "\n",
    "                    emissionWeights[predictedTagSequence[i]]['#UNK#'][0] -= 1\n",
    "                    emissionWeights[predictedTagSequence[i]]['#UNK#'][1] += emissionWeights[predictedTagSequence[i]]['#UNK#'][0]\n",
    "\n",
    "                transitionWeights[tagSequence[i-1]][tagSequence[i]][0] += 1\n",
    "                transitionWeights[tagSequence[i-1]][tagSequence[i]][1] += transitionWeights[tagSequence[i-1]][tagSequence[i]][0]\n",
    "                transitionWeights[tagSequence[i]][tagSequence[i+1]][0] += 1\n",
    "                transitionWeights[tagSequence[i]][tagSequence[i+1]][1] += transitionWeights[tagSequence[i]][tagSequence[i+1]][0]\n",
    "\n",
    "                transitionWeights[predictedTagSequence[i-1]][predictedTagSequence[i]][0] -= 1\n",
    "                transitionWeights[predictedTagSequence[i-1]][predictedTagSequence[i]][1] += transitionWeights[predictedTagSequence[i-1]][predictedTagSequence[i]][0]\n",
    "                transitionWeights[predictedTagSequence[i]][predictedTagSequence[i+1]][0] -= 1\n",
    "                transitionWeights[predictedTagSequence[i]][predictedTagSequence[i+1]][1] += transitionWeights[predictedTagSequence[i]][predictedTagSequence[i+1]][0]\n",
    "\n",
    "    return emissionWeights, transitionWeights\n",
    "\n",
    "# emissionWeights, transitionWeights = updateWeights(observationSequence,tagSequence,predictedTagSequence, observationsList, emissionWeights, transitionWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(filePath,observationsList,emissionWeights,transitionWeights,numberOfIterations=4):\n",
    "    n = 0  \n",
    "\n",
    "    for t in range(numberOfIterations):\n",
    "        print ('Training model',t+1,'times')\n",
    "        observationSequence = []\n",
    "        tagSequence = []\n",
    "        for line in open(filePath, 'r'):\n",
    "            strippedLine = line.rstrip()\n",
    "            if strippedLine: \n",
    "                strippedLine = strippedLine.rsplit(' ', 1)\n",
    "                observation = strippedLine[0]  \n",
    "                tag = strippedLine[1] \n",
    "                observationSequence.append(observation)\n",
    "                tagSequence.append(tag)\n",
    "            else:\n",
    "                predictedTagSequence = viterbi(observationSequence,observationsList,emissionWeights,transitionWeights,tagsList)\n",
    "                emissionWeights, transitionWeights = updateWeights(observationSequence,tagSequence,predictedTagSequence, observationsList, emissionWeights, transitionWeights)\n",
    "                \n",
    "                n += 1\n",
    "                observationSequence = []\n",
    "                tagSequence = []\n",
    "\n",
    "    for tag in list(emissionWeights):\n",
    "        for observation in emissionWeights[tag]:\n",
    "            emissionWeights[tag][observation][1] /= (n+1)\n",
    "\n",
    "    for to_Y_Tag in list(transitionWeights):\n",
    "        for from_Y_Tag in transitionWeights[to_Y_Tag]:\n",
    "            transitionWeights[to_Y_Tag][from_Y_Tag][1] /= (n+1)\n",
    "\n",
    "    return emissionWeights, transitionWeights\n",
    "\n",
    "# trainModel(filepath,observationsList,emissionWeights,transitionWeights,numberOfIterations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 times\n",
      "Training model 2 times\n",
      "Training model 3 times\n",
      "Training model 4 times\n",
      "Finished writing to file ML Project/EN/test.p5.out\n"
     ]
    }
   ],
   "source": [
    "def sentimentAnalysis(inputPath,observationsList,emissionWeights,transitionWeights,tagsList,outputPath):\n",
    "    f = open(outputPath, 'w')\n",
    "\n",
    "    observationSequence = []\n",
    "    for line in open(inputPath, 'r'):\n",
    "        observation = line.rstrip()\n",
    "        if observation:\n",
    "            observationSequence.append(observation)\n",
    "        else:\n",
    "            predictedTagSequence = viterbi(observationSequence,observationsList,emissionWeights,transitionWeights,tagsList)\n",
    "            for i in range(len(observationSequence)):\n",
    "                f.write('%s %s\\n' % (observationSequence[i], predictedTagSequence[i]))\n",
    "            f.write('\\n')\n",
    "            observationSequence = []\n",
    "\n",
    "    print ('Finished writing to file %s' % (outputPath))\n",
    "    return f.close()\n",
    "\n",
    "\n",
    "ENtrain = \"ML Project/EN/train\"\n",
    "FRtrain = \"ML Project/FR/train\"\n",
    "ENinput = 'ML Project/EN/test.in'\n",
    "FRinput = 'ML Project/FR/test.in'\n",
    "ENoutput = 'ML Project/EN/test.p5.out'\n",
    "FRoutput = 'ML Project/FR/test.p5.out'\n",
    "file = open(ENtrain)\n",
    "sequence = prepare_data(file)\n",
    "observationsList,observationsDict = get_observations(sequence)\n",
    "tagsList = get_tags(sequence)\n",
    "transitionParameters = get_transition_parameters(tagsList,sequence)\n",
    "emissionParameters = get_smooth_emission_counts(sequence,observationsList,tagsList)\n",
    "emissionWeights = initialize_emission_weights(observationsList,tagsList,emissionParameters)\n",
    "transitionWeights = initialize_transition_weights(tagsList,transitionParameters)\n",
    "trainModel(ENtrain,observationsList,emissionWeights,transitionWeights,numberOfIterations=4)\n",
    "sentimentAnalysis(ENinput,observationsList,emissionWeights,transitionWeights,tagsList,ENoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
